#!/usr/bin/env node
"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
const fs_1 = require("fs");
const minimist = require("minimist");
const n3_1 = require("n3");
const Path = require("path");
const rdf_test_suite_1 = require("rdf-test-suite");
const LdfTestSuiteRunner_1 = require("../lib/LdfTestSuiteRunner");
const Logger_1 = require("../lib/factory/Logger");
const args = minimist(process.argv.slice(2));
if (args._.length < 2) {
    console.error(`${rdf_test_suite_1.Util.withColor(`rdf-test-suite-ldf executes test suites for engine-testing. 
rdf-test-suite-ldf currently supports testing for the following sourcetypes: HDT, LD-Files, RDFJ, SPARQL, TPF.`, rdf_test_suite_1.Util.COLOR_CYAN)}

${rdf_test_suite_1.Util.withColor('Usage:', rdf_test_suite_1.Util.COLOR_YELLOW)}
  rdf-test-suite-ldf path/to/myengine.js http://w3c.github.io/rdf-tests/sparql11/data-sparql11/manifest-all.ttl
  rdf-test-suite-ldf path/to/myengine.js http://w3c.github.io/rdf-tests/sparql11/data-sparql11/manifest-all.ttl \
-s http://www.w3.org/TR/sparql11-query/
  rdf-test-suite-ldf path/to/myengine.js http://w3c.github.io/rdf-tests/sparql11/data-sparql11/manifest-all.ttl \
-o earl -p earl-meta.json > earl.ttl

${rdf_test_suite_1.Util.withColor('Options:', rdf_test_suite_1.Util.COLOR_YELLOW)}
  -o    output format (detailed, summary, eurl, ... defaults to detailed)
  -p    file with earl properties, autogenerated from package.json if not available (only needed for EARL reports)
  -s    a specification URI to filter by (e.g. http://www.w3.org/TR/sparql11-query/)
  -c    enable HTTP caching at the given directory (disabled by default)
  -e    always exit with status code 0 on test errors
  -t    regex for test IRIs to run
  -i    JSON string with custom options that need to be passed to the engine
  -d    time out duration for test cases (in milliseconds, default 30000)
  -m    URL to local path mapping (e.g. 'https://w3c.github.io/json-ld-api/|/path/to/folder/')
  -r    The port number on which the mocking servers will start spawning (10000 by default)
  -v    Time (ms) to wait before stopping the server after each completed test
`);
    process.exit(1);
}
// Enable caching if needed
let cachePath = null;
if (args.c) {
    if (!args.c.endsWith('/')) {
        console.error(rdf_test_suite_1.Util.withColor(`Please give a correct caching path. The path '${args.c}' is invalid. Did you forget a trailing slash?`, rdf_test_suite_1.Util.COLOR_YELLOW));
        process.exit(1);
    }
    cachePath = Path.join(process.cwd(), (args.c === true ? '.rdf-test-suite-cache/' : args.c));
    Logger_1.logger.info(`Caching enabled in ${cachePath}`);
    if (!fs_1.existsSync(cachePath)) {
        fs_1.mkdirSync(cachePath);
    }
}
// Import the engine
const engine = require(Path.join(process.cwd(), args._[0]));
const defaultConfig = {
    exitWithStatusCode0: false,
    outputFormat: 'detailed',
    timeOutDuration: 30000,
};
const config = {
    cachePath,
    customEngingeOptions: args.i ? JSON.parse(args.i) : {},
    exitWithStatusCode0: !!args.e || defaultConfig.exitWithStatusCode0,
    outputFormat: args.o || defaultConfig.outputFormat,
    specification: args.s,
    testRegex: new RegExp(args.t),
    timeOutDuration: args.d || defaultConfig.timeOutDuration,
    urlToFileMapping: args.m,
    startPort: args.r,
    serverTerminationDelay: parseInt(args.v, 10) || 10,
};
// Fetch the manifest, run the tests, and print them
const ldfTestSuiteRunner = new LdfTestSuiteRunner_1.LdfTestSuiteRunner();
ldfTestSuiteRunner.runManifest(args._[1], engine, config)
    .then((testResults) => {
    switch (config.outputFormat) {
        case 'earl':
            if (!args.p) {
                throw new Error(`EARL reporting requires the -p argument to point to an earl-meta.json file.`);
            }
            // Create properties file if it does not exist
            if (!fs_1.existsSync(Path.join(process.cwd(), args.p))) {
                fs_1.writeFileSync(Path.join(process.cwd(), args.p), JSON.stringify(ldfTestSuiteRunner.packageJsonToEarlProperties(require(Path.join(process.cwd(), 'package.json'))), null, '  '));
            }
            ldfTestSuiteRunner.resultsToEarl(testResults, require(Path.join(process.cwd(), args.p)), new Date())
                .pipe(new n3_1.StreamWriter({ format: 'text/turtle', prefixes: require('../lib/prefixes.json') }))
                .pipe(process.stdout)
                .on('end', () => onEnd(testResults));
            break;
        case 'summary':
            ldfTestSuiteRunner.resultsToText(process.stdout, testResults, true);
            onEnd(testResults);
            break;
        default:
            ldfTestSuiteRunner.resultsToText(process.stdout, testResults, false);
            onEnd(testResults);
            break;
    }
}).catch(console.error);
function onEnd(testResults) {
    // Exit with status code 1 if there was at least one failing test
    if (!config.exitWithStatusCode0) {
        for (const testResult of testResults) {
            if (!testResult.skipped && !testResult.ok) {
                process.exit(1);
            }
        }
    }
}
//# sourceMappingURL=Runner.js.map